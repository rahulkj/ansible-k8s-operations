- import_playbook: ../playbooks/apt-update-playbook.yaml

- name: Install common packages on the hosts
  hosts: all
  any_errors_fatal: true
  tasks:
    - name: Configure sysctl and kernel modules for kubernetes
      ansible.builtin.stat:
        path: /etc/modules-load.d/containerd.conf
      register: containerd_conf_result

    - name: Set containerd kernel modules load file
      file:
        path: "/etc/modules-load.d/containerd.conf"
        state: "touch"
      when: not containerd_conf_result.stat.exists

    - name: Add containerd kernel modules
      blockinfile:
        path: "/etc/modules-load.d/containerd.conf"
        block: |
          overlay
          br_netfilter
      when: not containerd_conf_result.stat.exists

    - name: Load necessary kernel modules
      shell: |
        sudo modprobe overlay
        sudo modprobe br_netfilter

    - name: Check that the 99-kubernetes-cri.conf exists
      ansible.builtin.stat:
        path: /etc/sysctl.d/99-kubernetes-cri.conf
      register: kubernetes_cri_conf_result

    - name: Set system configurations for Kubernetes networking
      file:
        path: "/etc/sysctl.d/99-kubernetes-cri.conf"
        state: "touch"
      when: not kubernetes_cri_conf_result.stat.exists

    - name: Add sysctl conf for kubernetes networking
      blockinfile:
        path: "/etc/sysctl.d/99-kubernetes-cri.conf"
        block: |
          net.bridge.bridge-nf-call-iptables = 1
          net.ipv4.ip_forward = 1
          net.bridge.bridge-nf-call-ip6tables = 1
      when: not kubernetes_cri_conf_result.stat.exists

    - name: Check that the 99-disable-ipv6.conf exists
      ansible.builtin.stat:
        path: /etc/sysctl.d/99-disable-ipv6.conf
      register: ipv6_disable_conf_result

    - name: Set system configurations to disable IPv6
      file:
        path: "/etc/sysctl.d/99-disable-ipv6.conf"
        state: "touch"
      when: not ipv6_disable_conf_result.stat.exists

    - name: Add sysctl conf to disable IPv6
      blockinfile:
        path: "/etc/sysctl.d/99-disable-ipv6.conf"
        block: |
          net.ipv6.conf.all.disable_ipv6 = 1
          net.ipv6.conf.default.disable_ipv6 = 1
          net.ipv6.conf.lo.disable_ipv6 = 1
      when: not ipv6_disable_conf_result.stat.exists

    - name: Apply sysctl settings
      shell: |
        sudo sysctl --system

    - name: Disable swap on the hosts
      shell: |
        sudo swapoff -a
        sudo sed -i '/swap/ s/^\(.*\)$/#\1/g' /etc/fstab

    - name: Enable cgroups in ubuntu on rpi
      shell: |
        if [ -f /boot/cmdline.txt ]; then
          FOUND=$(cat /boot/cmdline.txt | grep "cgroup")
          if [ -z $FOUND ]; then
            sudo sed -i 's/$/ cgroup_enable=cpuset cgroup_enable=memory cgroup_memory=1/' /boot/cmdline.txt
          fi
        fi
      register: cgroups_enabled
    
    - name: Enable cgroups in 24.04 ubuntu on rpi
      shell: |
        ## Ubuntu 24.04 on rpi
        if [ -f /boot/firmware/cmdline.txt ]; then
          FOUND=$(cat /boot/firmware/cmdline.txt | grep "cgroup")
          if [ -z $FOUND ]; then
            sudo sed -i 's/$/ cgroup_enable=memory cgroup_memory=1/' /boot/firmware/cmdline.txt
          fi
        fi
      register: cgroups_enabled

    - name: Enable cgroups in 25.10 ubuntu on rpi
      shell: |
        ## Ubuntu 25.10 on rpi
        if [ -f /boot/firmware/current/cmdline.txt ]; then
          FOUND=$(cat /boot/firmware/current/cmdline.txt | grep "cgroup")
          if [ -z $FOUND ]; then
            sudo sed -i 's/$/ cgroup_enable=memory cgroup_memory=1/' /boot/firmware/current/cmdline.txt
          fi
        fi
      register: cgroups_enabled

    - name: Export reboot_required fact
      set_fact:
        reboot_required: "{{ cgroups_enabled }}"

- import_playbook: ../playbooks/reboot-playbook.yaml

- name: Install containerd and kubernetes packages
  hosts: all
  any_errors_fatal: true
  tasks:
    - name: install containerd network plugins and configure cgroups
      shell: |
        sudo apt-get install -y containerd containernetworking-plugins
        
        sudo mkdir -p /etc/containerd
        
        containerd config default | sed "s/ShimCgroup = ''/ShimCgroup = ''\n            SystemdCgroup = true/" | sudo tee /etc/containerd/config.toml

        sudo systemctl restart containerd

    - name: Check that the crictl.yaml exists
      ansible.builtin.stat:
        path: /etc/crictl.yaml
      register: crictl_result

    - name: Set system configurations for Kubernetes networking
      file:
        path: "/etc/crictl.yaml"
        state: "touch"
      when: not crictl_result.stat.exists

    - name: Add conf for crictl
      blockinfile:
        path: "/etc/crictl.yaml"
        block: |
          runtime-endpoint: unix:///run/containerd/containerd.sock
          image-endpoint: unix:///run/containerd/containerd.sock
          timeout: 2
          debug: true
          pull-image-on-create: false

    - name: Check that the kubernetes keyring file exists
      ansible.builtin.stat:
        path: /etc/apt/keyrings/kubernetes-apt-keyring.gpg
      register: kubernetes_keyring_result

    - name: install and configure dependencies
      shell: |
        sudo apt-get update && sudo apt-get install -y apt-transport-https curl ipvsadm
        curl -fsSL https://pkgs.k8s.io/core:/stable:/v{{k8s.version}}/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
        sudo chmod 644 /etc/apt/keyrings/kubernetes-apt-keyring.gpg
      when: not kubernetes_keyring_result.stat.exists

    - name: Check that the kubernetes repo file exists
      ansible.builtin.stat:
        path: /etc/apt/sources.list.d/kubernetes.list
      register: kubernetes_repo_conf_result

    - name: Create kubernetes repo file
      file:
        path: "/etc/apt/sources.list.d/kubernetes.list"
        state: "touch"
      when: not kubernetes_repo_conf_result.stat.exists

    - name: Add K8s Source
      blockinfile:
        path: "/etc/apt/sources.list.d/kubernetes.list"
        block: |
          deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v{{k8s.version}}/deb/ /

    - name: install kubernetes packages
      shell: |
        sudo apt-get update
        sudo apt-mark unhold kubelet kubeadm kubectl
        sudo apt-get purge -y kubelet kubeadm kubectl
        sudo apt-get install -y kubelet kubeadm kubectl
        sudo apt-mark hold kubelet kubeadm kubectl

    - name: install nfs-common packages
      shell: |
        sudo apt-get update
        sudo apt-get install -y nfs-common
      register: reboot_required

    - name: Export reboot_required fact
      set_fact:
        reboot_required: "{{ reboot_required }}"

- import_playbook: ../playbooks/reboot-playbook.yaml

- hosts: control_plane
  any_errors_fatal: true
  tasks:
    - name: Initialize the Kubernetes Cluster
      become_user: root
      shell: |
        TOKEN=$(kubeadm token generate)
        IP_ADDR=$(hostname -I | awk '{print $1}')
        kubeadm init --pod-network-cidr=10.244.0.0/16 --token $TOKEN --control-plane-endpoint "$IP_ADDR:6443" --upload-certs
      args:
        chdir: $HOME
        creates: cluster_initialized.txt

    - name: Install Pod network - Canal
      shell: |
        export KUBECONFIG=/etc/kubernetes/admin.conf
        VERSION=$(curl https://api.github.com/repos/projectcalico/calico/releases | jq -r '.[0] | .tag_name')
        
        curl https://raw.githubusercontent.com/projectcalico/calico/$VERSION/manifests/canal.yaml -O
        kubectl apply -f canal.yaml
        rm canal.yaml

    - name: Generate the join command for worker nodes
      become_user: root
      shell: |
        export KUBECONFIG=/etc/kubernetes/admin.conf
        kubeadm token create --print-join-command
      register: kubernetes_join_command

    - name: Join Command Output
      debug:
        msg: "{{ kubernetes_join_command.stdout }}"

    - name: Copy join command to local file.
      local_action: copy content="{{ kubernetes_join_command.stdout_lines[0] }}" dest="/tmp/kubernetes_join_command" mode=0777

- hosts: worker_nodes
  become: true
  gather_facts: true

  tasks:
    - name: Copy join command from control plane to worker nodes.
      copy:
        src: /tmp/kubernetes_join_command
        dest: /tmp/kubernetes_join_command
        mode: 0777

    - name: Join the Worker nodes to the cluster.
      command: sh /tmp/kubernetes_join_command

- hosts: control_plane
  any_errors_fatal: true
  tasks:
    - name: Install Loadbalancer
      shell: |
        export KUBECONFIG=/etc/kubernetes/admin.conf

        kubectl get configmap kube-proxy -n kube-system -o yaml | sed -e "s/strictARP: false/strictARP: true/" | kubectl apply -f - -n kube-system

        VERSION=$(curl https://api.github.com/repos/metallb/metallb/releases | jq -r '.[0] | .tag_name')
        wget https://raw.githubusercontent.com/metallb/metallb/$VERSION/config/manifests/metallb-native.yaml -O metallb-native-$VERSION.yaml
        kubectl apply -f metallb-native-$VERSION.yaml
        kubectl -n metallb-system rollout status deployment/controller --watch=true
        rm metallb-native-$VERSION.yaml

    - name: Copy metallb config file
      copy:
        src: ../temp/metal-lb-config.yaml
        dest: /tmp/metal-lb-config.yaml

    - name: Apply metallb config file
      shell: |
        export KUBECONFIG=/etc/kubernetes/admin.conf
        kubectl apply -f /tmp/metal-lb-config.yaml

    - name: Install helm cli
      become_user: root
      shell: snap install helm --classic

    - name: Create NFS storage class
      shell: |
        export KUBECONFIG=/etc/kubernetes/admin.conf
        helm repo add nfs-subdir-external-provisioner https://kubernetes-sigs.github.io/nfs-subdir-external-provisioner

        helm upgrade --install nfs-subdir-external-provisioner nfs-subdir-external-provisioner/nfs-subdir-external-provisioner \
        --create-namespace \
        --namespace nfs-provisioner \
        --set nfs.server={{ lookup('ansible.builtin.env', 'NFS_SERVER') }} \
        --set nfs.path={{ lookup('ansible.builtin.env', 'NFS_MOUNT') }} \
        --set storageClass.name=nfs-storage \
        --set storageClass.defaultClass=true

    - name: Copy traefik values file
      copy:
        src: ../templates/traefik-values.yaml
        dest: /tmp/traefik-values.yaml

    - name: Install traefik ingress controller
      shell: |
        export KUBECONFIG=/etc/kubernetes/admin.conf

        helm repo add traefik https://traefik.github.io/charts
        helm upgrade --install traefik traefik/traefik \
          --create-namespace --namespace traefik \
          -f /tmp/traefik-values.yaml

    - name: Install headlamp dashboard
      shell: |
        export KUBECONFIG=/etc/kubernetes/admin.conf
        kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/headlamp/main/kubernetes-headlamp.yaml

    - name: Copy headlamp ingress file
      copy:
        src: ../temp/headlamp-ingress.yaml
        dest: /tmp/headlamp-ingress.yaml

    - name: Expose headlamp dashboard via ingress
      shell: |
        export KUBECONFIG=/etc/kubernetes/admin.conf
        kubectl apply -f /tmp/headlamp-ingress.yaml

    - name: Create service account user and assign permissions for accessing headlamp dashboard
      shell: |
        export KUBECONFIG=/etc/kubernetes/admin.conf
        kubectl -n kube-system create serviceaccount headlamp-admin
        kubectl create clusterrolebinding headlamp-admin \
          --serviceaccount=kube-system:headlamp-admin \
          --clusterrole=cluster-admin
    
    - name: Join Command Output
      debug:
        msg: 
        - "SSH to the host, and run the commands"
        - "mkdir -p $HOME/.kube"
        - "sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config"
        - "sudo chown $(id -u):$(id -g) $HOME/.kube/config"
