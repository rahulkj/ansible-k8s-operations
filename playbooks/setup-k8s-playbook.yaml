- name: Update apt-packages on linux vms
  hosts: all
  tasks:
    - name: Ping the hosts
      ansible.builtin.ping:
    - name: Update Apt Cache
      ansible.builtin.apt:
        update_cache: true
    - name: Apt Update
      ansible.builtin.apt:
        name: "*"
        state: latest
      register: apt_update
    - name: Apt Clean
      ansible.builtin.apt:
        autoclean: true
    - name: System Reboot
      ansible.builtin.reboot:
      when:
        - apt_update.changed

- name: Install common packages on the hosts
  hosts: all
  tasks:
    - name: Check that the containerd.conf exists
      ansible.builtin.stat:
        path: /etc/modules-load.d/containerd.conf
      register: containerd_conf_result
    - name: Create containerd config file
      file:
        path: "/etc/modules-load.d/containerd.conf"
        state: "touch"
      when: not containerd_conf_result.stat.exists
    - name: Add conf for containerd
      blockinfile:
        path: "/etc/modules-load.d/containerd.conf"
        block: |
          overlay
          br_netfilter
      when: not containerd_conf_result.stat.exists
    - name: modprobe
      shell: |
        sudo modprobe overlay
        sudo modprobe br_netfilter
    - name: Check that the 99-kubernetes-cri.conf exists
      ansible.builtin.stat:
        path: /etc/sysctl.d/99-kubernetes-cri.conf
      register: kubernetes_cri_conf_result
    - name: Set system configurations for Kubernetes networking
      file:
        path: "/etc/sysctl.d/99-kubernetes-cri.conf"
        state: "touch"
      when: not kubernetes_cri_conf_result.stat.exists
    - name: Add conf for containerd
      blockinfile:
        path: "/etc/sysctl.d/99-kubernetes-cri.conf"
        block: |
          net.bridge.bridge-nf-call-iptables = 1
          net.ipv4.ip_forward = 1
          net.bridge.bridge-nf-call-ip6tables = 1
      when: not kubernetes_cri_conf_result.stat.exists
    - name: Apply new settings
      command: sudo sysctl --system
    - name: Disable swap
      shell: |
        sudo swapoff -a
        sudo sed -i '/swap/ s/^\(.*\)$/#\1/g' /etc/fstab
    - name: install containerd network plugins and configure cgroups
      shell: |
        sudo apt-get update && sudo apt-get install -y containerd containernetworking-plugins
        sudo mkdir -p /etc/containerd
        containerd config default | sed "s/ShimCgroup = ''/ShimCgroup = ''\n            SystemdCgroup = true/" | sudo tee /etc/containerd/config.toml
        sudo sed -i 's/SystemdCgroup = false/SystemdCgroup = true/g' /etc/containerd/config.toml
        sudo systemctl restart containerd
    - name: create local storage folders for persistent volume
      shell: |
        sudo mkdir -p /data/volumes
        sudo chmod 777 /data/volumes
    - name: Check that the crictl.yaml exists
      ansible.builtin.stat:
        path: /etc/crictl.yaml
      register: crictl_result
    - name: Set system configurations for Kubernetes networking
      file:
        path: "/etc/crictl.yaml"
        state: "touch"
      when: not crictl_result.stat.exists
    - name: Add conf for crictl
      blockinfile:
        path: "/etc/crictl.yaml"
        block: |
          runtime-endpoint: unix:///run/containerd/containerd.sock
          image-endpoint: unix:///run/containerd/containerd.sock
          timeout: 2
          debug: true
          pull-image-on-create: false
    - name: Check that the kubernetes keyring file exists
      ansible.builtin.stat:
        path: /etc/apt/keyrings/kubernetes-apt-keyring.gpg
      register: kubernetes_keyring_result
    - name: install and configure dependencies
      shell: |
        sudo apt-get update && sudo apt-get install -y apt-transport-https curl ipvsadm
        curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.32/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
        sudo chmod 644 /etc/apt/keyrings/kubernetes-apt-keyring.gpg
      when: not kubernetes_keyring_result.stat.exists
    - name: Check that the kubernetes repo file exists
      ansible.builtin.stat:
        path: /etc/apt/sources.list.d/kubernetes.list
      register: kubernetes_repo_conf_result
    - name: Create kubernetes repo file
      file:
        path: "/etc/apt/sources.list.d/kubernetes.list"
        state: "touch"
      when: not kubernetes_repo_conf_result.stat.exists
    - name: Add K8s Source
      blockinfile:
        path: "/etc/apt/sources.list.d/kubernetes.list"
        block: |
          deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.32/deb/ /
    - name: install kubernetes packages
      shell: |
        sudo apt-get update
        sudo apt-mark unhold kubelet kubeadm kubectl
        sudo apt-get purge -y kubelet kubeadm kubectl
        sudo apt-get install -y kubelet kubeadm kubectl
        sudo apt-mark hold kubelet kubeadm kubectl

- hosts: control_plane
  tasks:
    - name: initialize the cluster
      become_user: root
      shell: |
        TOKEN=$(kubeadm token generate)
        IP_ADDR=$(hostname -I | awk '{print $1}')
        kubeadm init --pod-network-cidr=10.244.0.0/16 --token $TOKEN --control-plane-endpoint "$IP_ADDR:6443" --upload-certs
      args:
        chdir: $HOME
        creates: cluster_initialized.txt
    - name: Install Pod network
      shell: |
        export KUBECONFIG=/etc/kubernetes/admin.conf
        VERSION=$(curl https://api.github.com/repos/projectcalico/calico/releases | jq -r '.[0] | .tag_name')
        
        curl https://raw.githubusercontent.com/projectcalico/calico/$VERSION/manifests/canal.yaml -O
        kubectl apply -f canal.yaml
    - name: Get the token for joining the worker nodes
      become_user: root
      shell: |
        export KUBECONFIG=/etc/kubernetes/admin.conf
        kubeadm token create --print-join-command
      register: kubernetes_join_command
    - name: Join Command Output
      debug:
        msg: "{{ kubernetes_join_command.stdout }}"
    - name: Copy join command to local file.
      local_action: copy content="{{ kubernetes_join_command.stdout_lines[0] }}" dest="/tmp/kubernetes_join_command" mode=0777

- hosts: worker_nodes
  become: true
  gather_facts: true

  tasks:
    - name: Copy join command from Ansiblehost to the worker nodes.
      copy:
        src: /tmp/kubernetes_join_command
        dest: /tmp/kubernetes_join_command
        mode: 0777
    - name: Join the Worker nodes to the cluster.
      command: sh /tmp/kubernetes_join_command
      register: joined_or_not

- hosts: control_plane
  tasks:
    - name: Install Loadbalancer
      shell: |
        export KUBECONFIG=/etc/kubernetes/admin.conf

        kubectl get configmap kube-proxy -n kube-system -o yaml | \
        sed -e "s/strictARP: false/strictARP: true/" | \
        kubectl apply -f - -n kube-system

        VERSION=$(curl https://api.github.com/repos/metallb/metallb/releases | jq -r '.[0] | .tag_name')
        wget https://raw.githubusercontent.com/metallb/metallb/$VERSION/config/manifests/metallb-native.yaml -O metallb-native-$VERSION.yaml
        kubectl apply -f metallb-native-$VERSION.yaml
        kubectl -n metallb-system rollout status deployment/controller --watch=true
    - name: Copy metallb config file
      copy:
        src: ../temp/metal-lb-config.yaml
        dest: /tmp/metal-lb-config.yaml
    - name: Apply metallb config file
      shell: |
        export KUBECONFIG=/etc/kubernetes/admin.conf
        kubectl apply -f /tmp/metal-lb-config.yaml
    - name: Copy storage class file
      copy:
        src: ../templates/storage-class.yaml
        dest: /tmp/sc.yaml
    - name: Create storage class
      shell: |
        export KUBECONFIG=/etc/kubernetes/admin.conf
        kubectl apply -f /tmp/sc.yaml
    - name: Copy persistent volume file
      copy:
        src: ../temp/pv.yaml
        dest: /tmp/pv.yaml
    - name: Create persistent volume
      shell: |
        export KUBECONFIG=/etc/kubernetes/admin.conf
        kubectl apply -f /tmp/pv.yaml
    - name: Install helm cli
      become_user: root
      shell: snap install helm --classic
    - name: Install kubernetes repository
      shell: |
        export KUBECONFIG=/etc/kubernetes/admin.conf
        helm repo add kubernetes-dashboard https://kubernetes.github.io/dashboard/
    - name: Install kubernetes dashboard
      shell: |
        export KUBECONFIG=/etc/kubernetes/admin.conf
        helm upgrade --install kubernetes-dashboard kubernetes-dashboard/kubernetes-dashboard --create-namespace --namespace kubernetes-dashboard
    - name: Change kubernetes dashboard service from ClusterIP to Loadbalancer
      shell: |
        export KUBECONFIG=/etc/kubernetes/admin.conf
        kubectl patch svc -n kubernetes-dashboard kubernetes-dashboard-kong-proxy --type='json' -p '[{"op":"replace","path":"/spec/type","value":"LoadBalancer"}]'
    - name: Copy manifest to create admin user for accessing kubernetes dashboard
      copy:
        src: ../templates/kubernetes-dashboard-user.yaml
        dest: /tmp/kubernetes-dashboard-user.yaml
    - name: Create admin user for accessing kubernetes dashboard
      shell: |
        export KUBECONFIG=/etc/kubernetes/admin.conf
        kubectl apply -f /tmp/kubernetes-dashboard-user.yaml
    - name: Install nginx ingress controller
      shell: |
        export KUBECONFIG=/etc/kubernetes/admin.conf
        VERSION=$(curl https://api.github.com/repos/kubernetes/ingress-nginx/releases | jq -r '.[0] | .tag_name')
        wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/${VERSION}/deploy/static/provider/cloud/deploy.yaml -O ingress-nginx-deploy-$VERSION.yaml 
        kubectl apply -f ingress-nginx-deploy-$VERSION.yaml
    - name: Change nginx service from ClusterIP to NodePort
      shell: |
        export KUBECONFIG=/etc/kubernetes/admin.conf
        kubectl patch svc -n ingress-nginx ingress-nginx-controller --type='json' -p '[{"op":"replace","path":"/spec/type","value":"NodePort"}]'
    - name: Join Command Output
      debug:
        msg: 
        - "SSH to the host, and run the commands"
        - "mkdir -p $HOME/.kube"
        - "sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config"
        - "sudo chown $(id -u):$(id -g) $HOME/.kube/config"
