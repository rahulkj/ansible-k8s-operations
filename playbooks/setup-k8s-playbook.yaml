---
- import_playbook: ../playbooks/sync-time-playbook.yaml

# =========================
# APT UPDATE + UPGRADE
# =========================
- import_playbook: ../playbooks/apt-update-playbook.yaml
- import_playbook: ../playbooks/reboot-playbook.yaml

# =========================
# KERNEL / SYSTEM TUNING
# =========================
- name: Configure kernel, sysctl, cgroups
  hosts: all
  become: true
  any_errors_fatal: true

  tasks:
    - name: Load kernel modules
      ansible.builtin.modprobe:
        name: "{{ item }}"
        state: present
      loop:
        - overlay
        - br_netfilter

    - name: Configure Kubernetes sysctl
      ansible.builtin.copy:
        dest: /etc/sysctl.d/99-kubernetes-cri.conf
        content: |
          net.bridge.bridge-nf-call-iptables = 1
          net.ipv4.ip_forward = 1
          net.bridge.bridge-nf-call-ip6tables = 1

    - name: Disable IPv6
      ansible.builtin.copy:
        dest: /etc/sysctl.d/99-disable-ipv6.conf
        content: |
          net.ipv6.conf.all.disable_ipv6 = 1
          net.ipv6.conf.default.disable_ipv6 = 1
          net.ipv6.conf.lo.disable_ipv6 = 1

    - name: Apply sysctl settings
      ansible.builtin.command: sysctl --system

    - name: Disable swap
      ansible.builtin.shell: |
        swapoff -a
        sed -i '/swap/ s/^/#/' /etc/fstab

    - name: Enable cgroups (Raspberry Pi)
      ansible.builtin.shell: |
        FILE=""
        for f in /boot/cmdline.txt /boot/firmware/cmdline.txt /boot/firmware/current/cmdline.txt; do
          [ -f "$f" ] && FILE="$f"
        done

        if [ -n "$FILE" ] && ! grep -q cgroup "$FILE"; then
          sed -i 's/$/ cgroup_enable=cpuset cgroup_enable=memory cgroup_memory=1/' "$FILE"
          echo "changed"
        fi
      register: cgroup_result
      changed_when: "'changed' in cgroup_result.stdout"

    - name: Mark reboot required (kernel/cgroups)
      ansible.builtin.set_fact:
        reboot_required: true
      when: cgroup_result.changed

# =========================
# REBOOT AFTER KERNEL CHANGES
# =========================
- import_playbook: ../playbooks/reboot-playbook.yaml

# =========================
# CONTAINERD + K8S PACKAGES
# =========================
- name: Install containerd and Kubernetes packages
  hosts: all
  become: true
  any_errors_fatal: true

  tasks:
    # --------------------------------------------------
    # Base packages (single apt transaction)
    # --------------------------------------------------
    - name: Install containerd and base networking packages
      ansible.builtin.apt:
        name:
          - containerd
          - containernetworking-plugins
          - net-tools
          - apt-transport-https
          - curl
          - ipvsadm
          - nfs-common
          - monit
        state: present
        update_cache: yes

    # Configure monit to monitor network
    - name: Configure monit for network monitoring
      ansible.builtin.copy:
        dest: /etc/monit/conf.d/network.conf
        content: |
          check host internet with address 1.1.1.1
            if failed ping count 3 with timeout 3 seconds then restart
            depends on systemd-networkd

          check process systemd-networkd matching "systemd-networkd"
            start program = "/bin/systemctl start systemd-networkd.service"
            stop  program = "/bin/systemctl stop systemd-networkd.service"
        mode: "0644"

    - name: Enable and start monit
      ansible.builtin.systemd:
        name: monit
        state: started
        enabled: true

    # --------------------------------------------------
    # Containerd configuration (correct + idempotent)
    # --------------------------------------------------

    - name: Ensure containerd config directory exists
      ansible.builtin.file:
        path: /etc/containerd
        state: directory
        mode: "0755"

    - name: Check if containerd config exists
      ansible.builtin.stat:
        path: /etc/containerd/config.toml
      register: containerd_config_stat

    - name: Generate default containerd config
      ansible.builtin.command: containerd config default
      register: containerd_config
      changed_when: true
      when: not containerd_config_stat.stat.exists

    - name: Write containerd config
      ansible.builtin.copy:
        dest: /etc/containerd/config.toml
        content: "{{ containerd_config.stdout }}"
        mode: "0644"
      when: not containerd_config_stat.stat.exists

    - name: Enable systemd cgroups in containerd
      ansible.builtin.replace:
        path: /etc/containerd/config.toml
        regexp: 'SystemdCgroup = false'
        replace: 'SystemdCgroup = true'
      notify: Restart containerd

    # --------------------------------------------------
    # crictl configuration (clean + idempotent)
    # --------------------------------------------------
    - name: Configure crictl
      ansible.builtin.copy:
        dest: /etc/crictl.yaml
        mode: "0644"
        content: |
          runtime-endpoint: unix:///run/containerd/containerd.sock
          image-endpoint: unix:///run/containerd/containerd.sock
          timeout: 2
          debug: true
          pull-image-on-create: false

    # --------------------------------------------------
    # Kubernetes APT repository (modern + idempotent)
    # --------------------------------------------------

    - name: Ensure apt keyrings directory exists
      ansible.builtin.file:
        path: /etc/apt/keyrings
        state: directory
        mode: "0755"

    - name: Install required packages
      ansible.builtin.apt:
        name:
          - ca-certificates
          - curl
          - gnupg
        state: present
        update_cache: yes

    - name: Remove existing Kubernetes keyring (fix bad runs)
      ansible.builtin.file:
        path: /etc/apt/keyrings/kubernetes-apt-keyring.gpg
        state: absent

    - name: Install Kubernetes signing key (official method)
      ansible.builtin.shell: |
        curl -fsSL https://pkgs.k8s.io/core:/stable:/v{{ k8s.version }}/deb/Release.key \
        | gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
      args:
        creates: /etc/apt/keyrings/kubernetes-apt-keyring.gpg

    - name: Set permissions on Kubernetes keyring
      ansible.builtin.file:
        path: /etc/apt/keyrings/kubernetes-apt-keyring.gpg
        mode: "0644"

    - name: Add Kubernetes apt repository
      ansible.builtin.apt_repository:
        repo: "deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v{{ k8s.version }}/deb/ /"
        filename: kubernetes
        state: present

    - name: Update apt cache
      ansible.builtin.apt:
        update_cache: yes

    # --------------------------------------------------
    # Kubernetes packages (controlled + safe)
    # --------------------------------------------------
    - name: Unhold Kubernetes packages
      ansible.builtin.command: apt-mark unhold kubelet kubeadm kubectl
      changed_when: false

    - name: Install Kubernetes components
      ansible.builtin.apt:
        name:
          - kubelet
          - kubeadm
          - kubectl
        state: present
        update_cache: yes

    - name: Hold Kubernetes packages
      ansible.builtin.command: apt-mark hold kubelet kubeadm kubectl
      changed_when: false

    # --------------------------------------------------
    # Reboot detection (correct)
    # --------------------------------------------------
    - name: Check if reboot is required
      ansible.builtin.stat:
        path: /var/run/reboot-required
      register: reboot_flag

    - name: Accumulate reboot requirement
      ansible.builtin.set_fact:
        reboot_required: "{{ reboot_required | default(false) or reboot_flag.stat.exists }}"

  handlers:
    - name: Restart containerd
      ansible.builtin.systemd:
        name: containerd
        state: restarted
        enabled: true

- import_playbook: ../playbooks/reboot-playbook.yaml

- hosts: control_plane
  any_errors_fatal: true
  tasks:
    - name: Initialize the Kubernetes Cluster
      become_user: root
      shell: |
        TOKEN=$(kubeadm token generate)
        IP_ADDR=$(hostname -I | awk '{print $1}')
        kubeadm init --pod-network-cidr=10.244.0.0/16 --token $TOKEN --control-plane-endpoint "$IP_ADDR:6443" --upload-certs
      args:
        chdir: $HOME
        creates: cluster_initialized.txt

    - name: Install Pod network - Antrea
      shell: |

        VERSION=$(curl https://api.github.com/repos/antrea-io/antrea/releases | jq -r '.[0] | .tag_name')
        
        curl https://raw.githubusercontent.com/antrea-io/antrea/$VERSION/build/yamls/antrea.yml -O
        kubectl apply -f antrea.yml
        rm antrea.yml

    - name: Generate the join command for worker nodes
      become_user: root
      shell: |
        kubeadm token create --print-join-command
      register: kubernetes_join_command

    - name: Join Command Output
      debug:
        msg: "{{ kubernetes_join_command.stdout }}"

    - name: Copy join command to local file.
      local_action: copy content="{{ kubernetes_join_command.stdout_lines[0] }}" dest="/tmp/kubernetes_join_command" mode=0777

- hosts: worker_nodes
  become: true
  gather_facts: true

  tasks:
    - name: Copy join command from control plane to worker nodes.
      copy:
        src: /tmp/kubernetes_join_command
        dest: /tmp/kubernetes_join_command
        mode: 0777

    - name: Join the Worker nodes to the cluster.
      command: sh /tmp/kubernetes_join_command

- hosts: control_plane
  any_errors_fatal: true

  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf

  tasks:
    - name: Install Loadbalancer
      shell: |
        kubectl get configmap kube-proxy -n kube-system -o yaml | sed -e "s/strictARP: false/strictARP: true/" | kubectl apply -f - -n kube-system

        VERSION=$(curl https://api.github.com/repos/metallb/metallb/releases | jq -r '.[0] | .tag_name')
        wget https://raw.githubusercontent.com/metallb/metallb/$VERSION/config/manifests/metallb-native.yaml -O metallb-native-$VERSION.yaml
        kubectl apply -f metallb-native-$VERSION.yaml
        kubectl -n metallb-system rollout status deployment/controller --watch=true
        rm metallb-native-$VERSION.yaml

    - name: Copy metallb config file
      copy:
        src: ../temp/metal-lb-config.yaml
        dest: /tmp/metal-lb-config.yaml

    - name: Apply metallb config file
      shell: |
        kubectl apply -f /tmp/metal-lb-config.yaml

    - name: Install helm cli
      become_user: root
      shell: snap install helm --classic

    - name: Create NFS storage class
      shell: |
        helm repo add nfs-subdir-external-provisioner https://kubernetes-sigs.github.io/nfs-subdir-external-provisioner

        helm upgrade --install nfs-subdir-external-provisioner nfs-subdir-external-provisioner/nfs-subdir-external-provisioner \
        --create-namespace \
        --namespace nfs-provisioner \
        --set nfs.server={{ lookup('ansible.builtin.env', 'NFS_SERVER') }} \
        --set nfs.path={{ lookup('ansible.builtin.env', 'NFS_MOUNT') }} \
        --set storageClass.name=nfs-storage \
        --set storageClass.defaultClass=true

    - name: Copy traefik values file
      copy:
        src: ../templates/traefik-values.yaml
        dest: /tmp/traefik-values.yaml

    - name: Install traefik ingress controller
      shell: |
        helm repo add traefik https://traefik.github.io/charts
        helm upgrade --install traefik traefik/traefik \
          --create-namespace --namespace traefik \
          -f /tmp/traefik-values.yaml

    - name: Install headlamp dashboard
      shell: |
        kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/headlamp/main/kubernetes-headlamp.yaml

    - name: Copy headlamp ingress file
      copy:
        src: ../temp/headlamp-ingress.yaml
        dest: /tmp/headlamp-ingress.yaml

    - name: Expose headlamp dashboard via ingress
      shell: |
        kubectl apply -f /tmp/headlamp-ingress.yaml

    - name: Create service account user and assign permissions for accessing headlamp dashboard
      shell: |
        kubectl -n kube-system create serviceaccount headlamp-admin
        kubectl create clusterrolebinding headlamp-admin \
          --serviceaccount=kube-system:headlamp-admin \
          --clusterrole=cluster-admin

    - name: Register harbor docker secret in default namespace
      environment: 
        HARBOR_REGISTRY_URL: "{{ lookup('ansible.builtin.env', 'HARBOR_REGISTRY_URL') }}"
        HARBOR_USERNAME: "{{ lookup('ansible.builtin.env', 'HARBOR_USERNAME') }}"
        HARBOR_PASSWORD: "{{ lookup('ansible.builtin.env', 'HARBOR_PASSWORD') }}"
      shell: |
        SECRET=$(kubectl get secrets | grep harbor-registry-secret)
        
        if [ -z "$SECRET" ]; then
          kubectl create secret docker-registry harbor-registry-secret \
            --docker-server="$HARBOR_REGISTRY_URL" \
            --docker-username="$HARBOR_USERNAME" \
            --docker-password="$HARBOR_PASSWORD" \
            --namespace=default
        fi

    - name: Deploy and patch metrics server to work with self-signed kubelet certs
      shell: |
        curl -LO https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
        kubectl apply -f components.yaml

        kubectl -n kube-system patch deployment metrics-server \
          --type='json' \
          -p='[{"op": "add", "path": "/spec/template/spec/containers/0/args/-", "value": "--kubelet-insecure-tls"}]'
        
        kubectl -n kube-system rollout restart deployment metrics-server

        rm components.yaml
    
    - name: Join Command Output
      debug:
        msg: 
        - "SSH to the host, and run the commands"
        - "mkdir -p $HOME/.kube"
        - "sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config"
        - "sudo chown $(id -u):$(id -g) $HOME/.kube/config"
